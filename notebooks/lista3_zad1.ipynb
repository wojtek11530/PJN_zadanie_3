{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import fasttext\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 711: expected 6 fields, saw 7\\nSkipping line 36520: expected 6 fields, saw 7\\nSkipping line 42179: expected 6 fields, saw 7\\nSkipping line 83836: expected 6 fields, saw 7\\nSkipping line 97058: expected 6 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_hwbst = {\n",
    "    'min1000': pd.read_csv('csv_files/min1000.hwbst.csv', sep=';'),\n",
    "    'min200': pd.read_csv('csv_files/min200.hwbst.csv', sep=';'),\n",
    "    'min30': pd.read_csv('csv_files/min30.hwbst.csv', sep=';'),\n",
    "    'min8': pd.read_csv('csv_files/min8.hwbst.csv', sep=';', error_bad_lines=False)\n",
    "}\n",
    "\n",
    "data_wbst = {\n",
    "    'min1000': pd.read_csv('csv_files/min1000.wbst.csv', sep=';'),\n",
    "    'min200': pd.read_csv('csv_files/min200.wbst.csv', sep=';'),\n",
    "    'min30': pd.read_csv('csv_files/min30.wbst.csv', sep=';'),\n",
    "    'min8': pd.read_csv('csv_files/min8.wbst.csv', sep=';')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#load models fastext\n",
    "models_fasttext = {\n",
    "    'model_train_base_bow': fasttext.load_model(\"models/model_train_base_bow.bin\"),\n",
    "    'model_train_base_skip': fasttext.load_model(\"models/model_train_base_skip.bin\"),\n",
    "    'model_train_clean_bow': fasttext.load_model(\"models/model_train_clean_bow.bin\"),\n",
    "    'model_train_clean_skip': fasttext.load_model(\"models/model_train_clean_skip.bin\"),\n",
    "    'model_wiki_base_bow': fasttext.load_model(\"models/model_wiki_base_bow.bin\"),\n",
    "    'model_wiki_base_skip': fasttext.load_model(\"models/model_wiki_base_skip.bin\"),\n",
    "    'model_wiki_clean_bow': fasttext.load_model(\"models/model_wiki_clean_bow.bin\"),\n",
    "    'model_wiki_clean_skip': fasttext.load_model(\"models/model_wiki_clean_skip.bin\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_worldvec = {\n",
    "    'word2vec_train_base': Word2Vec.load(\"models/word2vec_train_base.model\"),\n",
    "    'word2vec_train_clean': Word2Vec.load(\"models/word2vec_train_clean.model\"),\n",
    "    'word2vec_wiki_base': Word2Vec.load(\"models/word2vec_wiki_base.model\"),\n",
    "    'word2vec_wiki_clean': Word2Vec.load(\"models/word2vec_wiki_clean.model\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HWBST test\n",
      "Testing min1000\n",
      "Testing model word2vec_train_base F1 score: 0.6849397590361446 Accuracy score 0.5208428767750801\n",
      "Testing model word2vec_train_clean F1 score: 0.6876800354531354 Accuracy score 0.524018573237653\n",
      "Testing model word2vec_wiki_base F1 score: 0.6796324208683814 Accuracy score 0.5147297098247164\n",
      "Testing model word2vec_wiki_clean F1 score: 0.8162504902601647 Accuracy score 0.6895466342702523\n",
      "Testing model model_train_base_bow F1 score: 0.6092824113718103 Accuracy score 0.4381064972168859\n",
      "Testing model model_train_base_skip F1 score: 0.649256462290828 Accuracy score 0.48066597704546576\n",
      "Testing model model_train_clean_bow F1 score: 0.6432533582837666 Accuracy score 0.47411457563666815\n",
      "Testing model model_train_clean_skip F1 score: 0.6778038296209457 Accuracy score 0.5126348455741097\n",
      "Testing model model_wiki_base_bow F1 score: 0.752435089875557 Accuracy score 0.6031229988670509\n",
      "Testing model model_wiki_base_skip F1 score: 0.8496061653538846 Accuracy score 0.7385350475346042\n",
      "Testing model model_wiki_clean_bow F1 score: 0.792649201581968 Accuracy score 0.6565193832816117\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8461735201341328 Accuracy score 0.7333628885276587\n",
      "Testing min200\n",
      "Testing model word2vec_train_base F1 score: 0.7090980856522597 Accuracy score 0.5493043877083015\n",
      "Testing model word2vec_train_clean F1 score: 0.7195524028374463 Accuracy score 0.5619538077403246\n",
      "Testing model word2vec_wiki_base F1 score: 0.6929513875374615 Accuracy score 0.5301649693288071\n",
      "Testing model word2vec_wiki_clean F1 score: 0.8057914064510092 Accuracy score 0.6747492948918834\n",
      "Testing model model_train_base_bow F1 score: 0.6287283321805109 Accuracy score 0.4585001987099141\n",
      "Testing model model_train_base_skip F1 score: 0.6631656381543994 Accuracy score 0.49607165785209867\n",
      "Testing model model_train_clean_bow F1 score: 0.6516488046166529 Accuracy score 0.48329308183791386\n",
      "Testing model model_train_clean_skip F1 score: 0.677969526734834 Accuracy score 0.512824432148207\n",
      "Testing model model_wiki_base_bow F1 score: 0.75464945843565 Accuracy score 0.6059735257252912\n",
      "Testing model model_wiki_base_skip F1 score: 0.839562232825443 Accuracy score 0.723487511846168\n",
      "Testing model model_wiki_clean_bow F1 score: 0.7867514789607403 Accuracy score 0.648466876585858\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8385115222099918 Accuracy score 0.7219284032894133\n",
      "Testing min30\n",
      "Testing model word2vec_train_base F1 score: 0.7168959587274291 Accuracy score 0.55872005361032\n",
      "Testing model word2vec_train_clean F1 score: 0.7388871619521293 Accuracy score 0.5859009120039438\n",
      "Testing model word2vec_wiki_base F1 score: 0.7070772322710308 Accuracy score 0.546882806861711\n",
      "Testing model word2vec_wiki_clean F1 score: 0.8099249326686149 Accuracy score 0.6805662557781201\n",
      "Testing model model_train_base_bow F1 score: 0.6440592251285365 Accuracy score 0.4749906758940782\n",
      "Testing model model_train_base_skip F1 score: 0.6709259896729776 Accuracy score 0.5048070946085947\n",
      "Testing model model_train_clean_bow F1 score: 0.6639167266485798 Accuracy score 0.49691268492810076\n",
      "Testing model model_train_clean_skip F1 score: 0.6828595990884653 Accuracy score 0.5184410094898678\n",
      "Testing model model_wiki_base_bow F1 score: 0.7627824704872015 Accuracy score 0.616530603787659\n",
      "Testing model model_wiki_base_skip F1 score: 0.8378303533802901 Accuracy score 0.7209191496415399\n",
      "Testing model model_wiki_clean_bow F1 score: 0.7882242169355345 Accuracy score 0.6504703493431685\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8327851407565058 Accuracy score 0.7134805851394472\n",
      "Testing min8\n",
      "Testing model word2vec_train_base F1 score: 0.7506187217935653 Accuracy score 0.6007923560941505\n",
      "Testing model word2vec_train_clean F1 score: 0.7732131171380788 Accuracy score 0.6302750118539592\n",
      "Testing model word2vec_wiki_base F1 score: 0.7610911270983213 Accuracy score 0.614323735785144\n",
      "Testing model word2vec_wiki_clean F1 score: 0.8450709779179811 Accuracy score 0.7317081498173376\n",
      "Testing model model_train_base_bow F1 score: 0.68463288800775 Accuracy score 0.5204880688941718\n",
      "Testing model model_train_base_skip F1 score: 0.7160186488388458 Accuracy score 0.5576550221631509\n",
      "Testing model model_train_clean_bow F1 score: 0.6982582561157239 Accuracy score 0.5364030610497181\n",
      "Testing model model_train_clean_skip F1 score: 0.7170794733418884 Accuracy score 0.5589430198063893\n",
      "Testing model model_wiki_base_bow F1 score: 0.7887491079282359 Accuracy score 0.6511855744263957\n",
      "Testing model model_wiki_base_skip F1 score: 0.8610521551858672 Accuracy score 0.7560066592218576\n",
      "Testing model model_wiki_clean_bow F1 score: 0.8088834123532148 Accuracy score 0.6790967573974226\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8475680284864968 Accuracy score 0.7354603563916883\n"
     ]
    }
   ],
   "source": [
    "print(\"HWBST test\")\n",
    "for dataset, df in data_hwbst.items():\n",
    "    print(f'Testing {dataset}')\n",
    "    for name, model in models_worldvec.items():\n",
    "        prediction = []\n",
    "        for _, row in df.iterrows():\n",
    "            question = row['pytanie']\n",
    "            odp = row['odpowiedź']\n",
    "            term = 0\n",
    "            similarities = {}\n",
    "            try:\n",
    "                cosine_similarity(model.wv[question].reshape(1, -1), model.wv[odp].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            try:\n",
    "                similarities[row['termin 1']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 1']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 1']] = -2.0\n",
    "                term += 1\n",
    "            try:\n",
    "                similarities[row['termin 2']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 2']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 2']] = -2.0\n",
    "                term += 1\n",
    "            try:\n",
    "                similarities[row['termin 3']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 3']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 3']] = -2.0\n",
    "                term += 1\n",
    "            try:\n",
    "                similarities[row['termin 4']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 4']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 4']] = -2.0\n",
    "                term += 1\n",
    "            \n",
    "            if term != 3:\n",
    "                best = max(similarities, key=similarities.get)\n",
    "                if best == odp:\n",
    "                    prediction.append(1)\n",
    "                else:\n",
    "                    prediction.append(0)\n",
    "        \n",
    "        y_true = [1 for _ in range(len(prediction))]\n",
    "        print(f\"Testing model {name} F1 score: {f1_score(y_true, prediction)} Accuracy score {accuracy_score(y_true, prediction)}\")\n",
    "        \n",
    "    for name, model in models_fasttext.items():\n",
    "        prediction = []\n",
    "        for _, row in df.iterrows():\n",
    "            question = row['pytanie']\n",
    "            odp = row['odpowiedź']\n",
    "            similarities = {\n",
    "                row['termin 1']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 1']].reshape(1, -1))[0][0],\n",
    "                row['termin 2']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 2']].reshape(1, -1))[0][0],\n",
    "                row['termin 3']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 3']].reshape(1, -1))[0][0],\n",
    "                row['termin 4']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 4']].reshape(1, -1))[0][0]\n",
    "            }\n",
    "            best = max(similarities, key=similarities.get)\n",
    "            if best == odp:\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(0)\n",
    "        \n",
    "        y_true = [1 for _ in range(len(prediction))]\n",
    "        print(f\"Testing model {name} F1 score: {f1_score(y_true, prediction)} Accuracy score {accuracy_score(y_true, prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBST test\n",
      "Testing min1000\n",
      "Testing model word2vec_train_base F1 score: 0.7016504443504019 Accuracy score 0.5404172099087353\n",
      "Testing model word2vec_train_clean F1 score: 0.6970190964136005 Accuracy score 0.5349419124218052\n",
      "Testing model word2vec_wiki_base F1 score: 0.7135444244413851 Accuracy score 0.5546592031610141\n",
      "Testing model word2vec_wiki_clean F1 score: 0.8087576225112041 Accuracy score 0.678919452325151\n",
      "Testing model model_train_base_bow F1 score: 0.6530974761305604 Accuracy score 0.4848884492801407\n",
      "Testing model model_train_base_skip F1 score: 0.668471500695105 Accuracy score 0.5020331904604901\n",
      "Testing model model_train_clean_bow F1 score: 0.6914503487452363 Accuracy score 0.5284097153533356\n",
      "Testing model model_train_clean_skip F1 score: 0.6907913669064747 Accuracy score 0.5276404000439608\n",
      "Testing model model_wiki_base_bow F1 score: 0.7669060848353435 Accuracy score 0.621936476535883\n",
      "Testing model model_wiki_base_skip F1 score: 0.8527297944773674 Accuracy score 0.7432684910429718\n",
      "Testing model model_wiki_clean_bow F1 score: 0.822440792027954 Accuracy score 0.6984283987251346\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8512814038631485 Accuracy score 0.7410704473019013\n",
      "Testing min200\n",
      "Testing model word2vec_train_base F1 score: 0.7284708020904339 Accuracy score 0.5729092208720514\n",
      "Testing model word2vec_train_clean F1 score: 0.7329079307201458 Accuracy score 0.5784172661870504\n",
      "Testing model word2vec_wiki_base F1 score: 0.7259232440260681 Accuracy score 0.5697641375390736\n",
      "Testing model word2vec_wiki_clean F1 score: 0.7956183665361258 Accuracy score 0.660603204524034\n",
      "Testing model model_train_base_bow F1 score: 0.6832142167278348 Accuracy score 0.518849933988558\n",
      "Testing model model_train_base_skip F1 score: 0.6887232507814378 Accuracy score 0.5252310400469414\n",
      "Testing model model_train_clean_bow F1 score: 0.7146830073061513 Accuracy score 0.5560363796391374\n",
      "Testing model model_train_clean_skip F1 score: 0.704731141934258 Accuracy score 0.5440809740354995\n",
      "Testing model model_wiki_base_bow F1 score: 0.7783701447067783 Accuracy score 0.6371571072319202\n",
      "Testing model model_wiki_base_skip F1 score: 0.8507122987439939 Accuracy score 0.7402083027724805\n",
      "Testing model model_wiki_clean_bow F1 score: 0.8159277432802119 Accuracy score 0.6890861082587648\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8425654739165499 Accuracy score 0.7279595129822503\n",
      "Testing min30\n",
      "Testing model word2vec_train_base F1 score: 0.7423076923076924 Accuracy score 0.5902140672782875\n",
      "Testing model word2vec_train_clean F1 score: 0.7389265242313704 Accuracy score 0.5859504132231405\n",
      "Testing model word2vec_wiki_base F1 score: 0.7483997155049786 Accuracy score 0.5979542548657479\n",
      "Testing model word2vec_wiki_clean F1 score: 0.7985152190051967 Accuracy score 0.6646070192782996\n",
      "Testing model model_train_base_bow F1 score: 0.7128172289440868 Accuracy score 0.553780896522832\n",
      "Testing model model_train_base_skip F1 score: 0.7119490067788607 Accuracy score 0.5527335567658148\n",
      "Testing model model_train_clean_bow F1 score: 0.7360338893301562 Accuracy score 0.5823209049015501\n",
      "Testing model model_train_clean_skip F1 score: 0.7225901398086829 Accuracy score 0.565668202764977\n",
      "Testing model model_wiki_base_bow F1 score: 0.790512081578364 Accuracy score 0.6535923753665689\n",
      "Testing model model_wiki_base_skip F1 score: 0.8518863670524576 Accuracy score 0.7419878508588186\n",
      "Testing model model_wiki_clean_bow F1 score: 0.8264503441494592 Accuracy score 0.7042312526183494\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8424211196314368 Accuracy score 0.727744030163385\n",
      "Testing min8\n",
      "Testing model word2vec_train_base F1 score: 0.7475192943770673 Accuracy score 0.596830985915493\n",
      "Testing model word2vec_train_clean F1 score: 0.7629977395235611 Accuracy score 0.616811920157436\n",
      "Testing model word2vec_wiki_base F1 score: 0.775195436298331 Accuracy score 0.6329135759875798\n",
      "Testing model word2vec_wiki_clean F1 score: 0.8245530770447713 Accuracy score 0.7014804845222072\n",
      "Testing model model_train_base_bow F1 score: 0.7490126261075981 Accuracy score 0.5987371589347641\n",
      "Testing model model_train_base_skip F1 score: 0.7497034400948992 Accuracy score 0.5996204933586338\n",
      "Testing model model_train_clean_bow F1 score: 0.7661068948813176 Accuracy score 0.6208859517110515\n",
      "Testing model model_train_clean_skip F1 score: 0.7555066976100321 Accuracy score 0.6070797618268664\n",
      "Testing model model_wiki_base_bow F1 score: 0.8196404780753412 Accuracy score 0.6943990054308709\n",
      "Testing model model_wiki_base_skip F1 score: 0.8691405527396501 Accuracy score 0.7685663809461493\n",
      "Testing model model_wiki_clean_bow F1 score: 0.8495831686708444 Accuracy score 0.7385002944448079\n",
      "Testing model model_wiki_clean_skip F1 score: 0.8598179647866309 Accuracy score 0.7541058692665052\n"
     ]
    }
   ],
   "source": [
    "print(\"WBST test\")\n",
    "for dataset, df in data_wbst.items():\n",
    "    print(f'Testing {dataset}')\n",
    "    for name, model in models_worldvec.items():\n",
    "        prediction = []\n",
    "        for _, row in df.iterrows():\n",
    "            question = row['pytanie']\n",
    "            odp = row['odpowiedź']\n",
    "            term = 0\n",
    "            similarities = {}\n",
    "            try:\n",
    "                cosine_similarity(model.wv[question].reshape(1, -1), model.wv[odp].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            try:\n",
    "                similarities[row['termin 1']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 1']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 1']] = -2.0\n",
    "                term += 1\n",
    "            try:\n",
    "                similarities[row['termin 2']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 2']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 2']] = -2.0\n",
    "                term += 1\n",
    "            try:\n",
    "                similarities[row['termin 3']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 3']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 3']] = -2.0\n",
    "                term += 1\n",
    "            try:\n",
    "                similarities[row['termin 4']] = cosine_similarity(model.wv[question].reshape(1, -1), model.wv[row['termin 4']].reshape(1, -1))[0][0]\n",
    "            except KeyError:\n",
    "                similarities[row['termin 4']] = -2.0\n",
    "                term += 1\n",
    "            \n",
    "            if term != 3:\n",
    "                best = max(similarities, key=similarities.get)\n",
    "                if best == odp:\n",
    "                    prediction.append(1)\n",
    "                else:\n",
    "                    prediction.append(0)\n",
    "        \n",
    "        y_true = [1 for _ in range(len(prediction))]\n",
    "        print(f\"Testing model {name} F1 score: {f1_score(y_true, prediction)} Accuracy score {accuracy_score(y_true, prediction)}\")\n",
    "        \n",
    "    for name, model in models_fasttext.items():\n",
    "        prediction = []\n",
    "        for _, row in df.iterrows():\n",
    "            question = row['pytanie']\n",
    "            odp = row['odpowiedź']\n",
    "            similarities = {\n",
    "                row['termin 1']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 1']].reshape(1, -1))[0][0],\n",
    "                row['termin 2']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 2']].reshape(1, -1))[0][0],\n",
    "                row['termin 3']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 3']].reshape(1, -1))[0][0],\n",
    "                row['termin 4']: cosine_similarity(model[question].reshape(1, -1), model[row['termin 4']].reshape(1, -1))[0][0]\n",
    "            }\n",
    "            best = max(similarities, key=similarities.get)\n",
    "            if best == odp:\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                prediction.append(0)\n",
    "        \n",
    "        y_true = [1 for _ in range(len(prediction))]\n",
    "        print(f\"Testing model {name} F1 score: {f1_score(y_true, prediction)} Accuracy score {accuracy_score(y_true, prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
